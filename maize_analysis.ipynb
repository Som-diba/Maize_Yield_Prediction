{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maize_data = pd.read_csv('climate_data_csv/FAOSTAT_data_en_8-7-2023.csv')\n",
    "maize_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maize_data[\"Area\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Germany_maize = maize_data[maize_data[\"Area\"]==\"Germany\"]\n",
    "Germany_maize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Germany_maize = Germany_maize.pivot_table(index='Year', columns='Element', values='Value').reset_index()\n",
    "Germany_maize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Germany_maize.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Germany_maize.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Germany_maize.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your text file\n",
    "file_path = 'climate_data_txt/regional_averages_rr_year.txt'\n",
    "\n",
    "# Read the text file\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Find the start of the data section by looking for a line that starts with 'Jahr'\n",
    "data_start_index = 1\n",
    "for i, line in enumerate(lines):\n",
    "    if line.startswith('Jahr'):\n",
    "        data_start_index = i\n",
    "        break\n",
    "\n",
    "# Extract the header and data lines\n",
    "headers = lines[data_start_index].strip().split(';')\n",
    "data_lines = lines[data_start_index + 1:]\n",
    "\n",
    "# Parse data lines into a list of lists\n",
    "data = [line.strip().split(';') for line in data_lines]\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data, columns=headers)\n",
    "\n",
    "# Convert data types if necessary (e.g., float, int)\n",
    "df = df.apply(pd.to_numeric, errors='ignore')\n",
    "\n",
    "# Path to the output CSV file\n",
    "output_csv_path = 'climate_data_csv/germany_precipitation_data.csv'\n",
    "\n",
    "# Save DataFrame to CSV\n",
    "df.to_csv(output_csv_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precipitation_data = pd.read_csv('climate_data_csv/germany_precipitation_data.csv')\n",
    "precipitation_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del precipitation_data['Unnamed: 19']\n",
    "precipitation_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precipitation_data.rename(columns={'Jahr': 'Year','Deutschland':'pre'}, inplace=True)\n",
    "column_names = precipitation_data.columns.tolist()\n",
    "print(\"Column names:\", column_names)\n",
    "precipitation_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precipitation_data_up = precipitation_data.drop(precipitation_data.iloc[0:80].index, axis=0)\n",
    "precipitation_data_updated = precipitation_data_up.drop(precipitation_data.iloc[141:].index, axis=0)\n",
    "precipitation_data_updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precipitation_data_updated1 = precipitation_data_updated.drop(['Jahr.1', 'Brandenburg/Berlin', 'Brandenburg', 'Baden-Wuerttemberg', 'Bayern', 'Hessen', 'Mecklenburg-Vorpommern', 'Niedersachsen', 'Niedersachsen/Hamburg/Bremen', 'Nordrhein-Westfalen', 'Rheinland-Pfalz', 'Schleswig-Holstein', 'Saarland', 'Sachsen', 'Sachsen-Anhalt', 'Thueringen/Sachsen-Anhalt', 'Thueringen'], axis=1)\n",
    "precipitation_data_updated1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your text file\n",
    "file_path = 'climate_data_txt/regional_averages_tm_year.txt'\n",
    "\n",
    "# Read the text file\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Find the start of the data section by looking for a line that starts with 'Jahr'\n",
    "data_start_index = 1\n",
    "for i, line in enumerate(lines):\n",
    "    if line.startswith('Jahr'):\n",
    "        data_start_index = i\n",
    "        break\n",
    "\n",
    "# Extract the header and data lines\n",
    "headers = lines[data_start_index].strip().split(';')\n",
    "data_lines = lines[data_start_index + 1:]\n",
    "\n",
    "# Parse data lines into a list of lists\n",
    "data = [line.strip().split(';') for line in data_lines]\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data, columns=headers)\n",
    "\n",
    "# Convert data types if necessary (e.g., float, int)\n",
    "df = df.apply(pd.to_numeric, errors='ignore')\n",
    "\n",
    "# Path to the output CSV file\n",
    "output_csv_path = 'climate_data_csv/germany_temperature_data.csv'\n",
    "\n",
    "# Save DataFrame to CSV\n",
    "df.to_csv(output_csv_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature_data = pd.read_csv('climate_data_csv/germany_temperature_data.csv')\n",
    "temperature_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del temperature_data['Unnamed: 19']\n",
    "temperature_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature_data.rename(columns={'Jahr': 'Year','Deutschland':'tmp'}, inplace=True)\n",
    "column_names = temperature_data.columns.tolist()\n",
    "print(\"Column names:\", column_names)\n",
    "temperature_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature_data_up = temperature_data.drop(temperature_data.iloc[0:80].index, axis=0)\n",
    "temperature_data_updated = temperature_data_up.drop(temperature_data.iloc[141:].index, axis=0)\n",
    "temperature_data_updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature_data_updated1 = temperature_data_updated.drop(['Jahr.1', 'Brandenburg/Berlin', 'Brandenburg', 'Baden-Wuerttemberg', 'Bayern', 'Hessen', 'Mecklenburg-Vorpommern', 'Niedersachsen', 'Niedersachsen/Hamburg/Bremen', 'Nordrhein-Westfalen', 'Rheinland-Pfalz', 'Schleswig-Holstein', 'Saarland', 'Sachsen', 'Sachsen-Anhalt', 'Thueringen/Sachsen-Anhalt', 'Thueringen'], axis=1)\n",
    "temperature_data_updated1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your text file\n",
    "file_path = 'climate_data_txt/regional_averages_sd_year.txt'\n",
    "\n",
    "# Read the text file\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Find the start of the data section by looking for a line that starts with 'Jahr'\n",
    "data_start_index = 1\n",
    "for i, line in enumerate(lines):\n",
    "    if line.startswith('Jahr'):\n",
    "        data_start_index = i\n",
    "        break\n",
    "\n",
    "# Extract the header and data lines\n",
    "headers = lines[data_start_index].strip().split(';')\n",
    "data_lines = lines[data_start_index + 1:]\n",
    "\n",
    "# Parse data lines into a list of lists\n",
    "data = [line.strip().split(';') for line in data_lines]\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data, columns=headers)\n",
    "\n",
    "# Convert data types if necessary (e.g., float, int)\n",
    "df = df.apply(pd.to_numeric, errors='ignore')\n",
    "\n",
    "# Path to the output CSV file\n",
    "output_csv_path = 'climate_data_csv/germany_sun_duration_data.csv'\n",
    "\n",
    "# Save DataFrame to CSV\n",
    "df.to_csv(output_csv_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sun_duration_data = pd.read_csv('climate_data_csv/germany_sun_duration_data.csv')\n",
    "sun_duration_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del sun_duration_data['Unnamed: 19']\n",
    "sun_duration_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sun_duration_data.rename(columns={'Jahr': 'Year','Deutschland':'sun_d'}, inplace=True)\n",
    "column_names = sun_duration_data.columns.tolist()\n",
    "print(\"Column names:\", column_names)\n",
    "sun_duration_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sun_duration_data_up = sun_duration_data.drop(sun_duration_data.iloc[0:10].index, axis=0)\n",
    "sun_duration_data_updated = sun_duration_data_up.drop(sun_duration_data.iloc[71:].index, axis=0)\n",
    "sun_duration_data_updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sun_duration_data_updated1 = sun_duration_data_updated.drop(['Jahr.1', 'Brandenburg/Berlin', 'Brandenburg', 'Baden-Wuerttemberg', 'Bayern', 'Hessen', 'Mecklenburg-Vorpommern', 'Niedersachsen', 'Niedersachsen/Hamburg/Bremen', 'Nordrhein-Westfalen', 'Rheinland-Pfalz', 'Schleswig-Holstein', 'Saarland', 'Sachsen', 'Sachsen-Anhalt', 'Thueringen/Sachsen-Anhalt', 'Thueringen'], axis=1)\n",
    "sun_duration_data_updated1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your text file\n",
    "file_path = 'climate_data_txt/regional_averages_txas_year.txt'\n",
    "\n",
    "# Read the text file\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Find the start of the data section by looking for a line that starts with 'Jahr'\n",
    "data_start_index = 1\n",
    "for i, line in enumerate(lines):\n",
    "    if line.startswith('Jahr'):\n",
    "        data_start_index = i\n",
    "        break\n",
    "\n",
    "# Extract the header and data lines\n",
    "headers = lines[data_start_index].strip().split(';')\n",
    "data_lines = lines[data_start_index + 1:]\n",
    "\n",
    "# Parse data lines into a list of lists\n",
    "data = [line.strip().split(';') for line in data_lines]\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data, columns=headers)\n",
    "\n",
    "# Convert data types if necessary (e.g., float, int)\n",
    "df = df.apply(pd.to_numeric, errors='ignore')\n",
    "\n",
    "# Path to the output CSV file\n",
    "output_csv_path = 'climate_data_csv/germany_summer_days_data.csv'\n",
    "\n",
    "# Save DataFrame to CSV\n",
    "df.to_csv(output_csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summer_days_data = pd.read_csv('climate_data_csv/germany_summer_days_data.csv')\n",
    "summer_days_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del summer_days_data['Unnamed: 19']\n",
    "summer_days_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summer_days_data.rename(columns={'Jahr': 'Year','Deutschland':'sum_dys'}, inplace=True)\n",
    "column_names = summer_days_data.columns.tolist()\n",
    "print(\"Column names:\", column_names)\n",
    "summer_days_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summer_days_data_up = summer_days_data.drop(summer_days_data.iloc[0:10].index, axis=0)\n",
    "summer_days_data_updated = summer_days_data_up.drop(summer_days_data.iloc[71:].index, axis=0)\n",
    "summer_days_data_updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summer_days_data_updated1 = summer_days_data_updated.drop(['Jahr.1', 'Brandenburg/Berlin', 'Brandenburg', 'Baden-Wuerttemberg', 'Bayern', 'Hessen', 'Mecklenburg-Vorpommern', 'Niedersachsen', 'Niedersachsen/Hamburg/Bremen', 'Nordrhein-Westfalen', 'Rheinland-Pfalz', 'Schleswig-Holstein', 'Saarland', 'Sachsen', 'Sachsen-Anhalt', 'Thueringen/Sachsen-Anhalt', 'Thueringen'], axis=1)\n",
    "summer_days_data_updated1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "climate_data = precipitation_data_updated1.merge(temperature_data_updated1, on='Year', how='left')\n",
    "climate_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "climate_data = climate_data.merge(sun_duration_data_updated1, on='Year', how='left')\n",
    "climate_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "climate_data = climate_data.merge(summer_days_data_updated1, on='Year', how='left')\n",
    "climate_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Germany_maize_climate = Germany_maize.merge(climate_data, on='Year', how='outer')\n",
    "Germany_maize_climate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Germany_maize_climate.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Germany_maize_climate.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:,.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Germany_maize_climate.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pairplot\n",
    "sns.pairplot(Germany_maize_climate)\n",
    "plt.suptitle('Pairplot of Maize Data Features', y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the correlation matrix\n",
    "corr_matrix = Germany_maize_climate.corr()\n",
    "\n",
    "# Create a heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', linewidths=0.5)\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(Germany_maize_climate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "ax1.plot(Germany_maize_climate['Year'], Germany_maize_climate['Area harvested'], marker='o', label='Area harvested')\n",
    "ax1.plot(Germany_maize_climate['Year'], Germany_maize_climate['Production'], marker='o', label='Production')\n",
    "ax1.plot(Germany_maize_climate['Year'], Germany_maize_climate['Yield'], marker='o', label='Yield')\n",
    "ax1.plot(Germany_maize_climate['Year'], Germany_maize_climate['pre'], marker='o', label='Precipitation')\n",
    "ax1.plot(Germany_maize_climate['Year'], Germany_maize_climate['tmp'], marker='o', label='Temperature')\n",
    "ax1.plot(Germany_maize_climate['Year'], Germany_maize_climate['sun_d'], marker='o', label='Sun Duration')\n",
    "ax1.plot(Germany_maize_climate['Year'], Germany_maize_climate['sum_dys'], marker='o', label='Summer Days')\n",
    "ax1.set_xlabel('Year')\n",
    "ax1.set_ylabel('Values')\n",
    "ax1.set_title('Maize Data Over Time')\n",
    "ax1.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot([Germany_maize_climate['Area harvested'], Germany_maize_climate['Production'], Germany_maize_climate['Yield'], Germany_maize_climate['pre'], Germany_maize_climate['tmp'], Germany_maize_climate['sun_d'], Germany_maize_climate['sum_dys']],\n",
    "            labels=['Area harvested', 'Production', 'Yield', 'pre', 'tmp', 'sun_d', 'sum_dys'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Germany_maize_climate[['Year', 'Area harvested', 'Production', 'pre', 'tmp', 'sun_d', 'sum_dys']]\n",
    "y = Germany_maize_climate['Yield']\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "print(f'X_test:\\n{X_test}')\n",
    "print(f'X_train:\\n{X_train}')\n",
    "print(f'y_test:\\n{y_test}')\n",
    "print(f'y_train:\\n{y_train}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train the model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_test = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "train_rmse = mean_squared_error(y_train, y_pred_train, squared=False)\n",
    "test_rmse = mean_squared_error(y_test, y_pred_test, squared=False)\n",
    "\n",
    "print(f'Train RMSE: {train_rmse}')\n",
    "print(f'Test RMSE: {test_rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(X_train, y_train)\n",
    "y_pred_train_lr = linear_model.predict(X_train)\n",
    "y_pred_test_lr = linear_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Regressor\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred_train_rf = rf_model.predict(X_train)\n",
    "y_pred_test_rf = rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation for Linear Regression\n",
    "train_rmse_lr = mean_squared_error(y_train, y_pred_train_lr, squared=False)\n",
    "test_rmse_lr = mean_squared_error(y_test, y_pred_test_lr, squared=False)\n",
    "train_r2_lr = r2_score(y_train, y_pred_train_lr)\n",
    "test_r2_lr = r2_score(y_test, y_pred_test_lr)\n",
    "\n",
    "print('Linear Regression:')\n",
    "print(f'Train RMSE: {train_rmse_lr}, Test RMSE: {test_rmse_lr}')\n",
    "print(f'Train R²: {train_r2_lr}, Test R²: {test_r2_lr}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation for Random Forest\n",
    "train_rmse_rf = mean_squared_error(y_train, y_pred_train_rf, squared=False)\n",
    "test_rmse_rf = mean_squared_error(y_test, y_pred_test_rf, squared=False)\n",
    "train_r2_rf = r2_score(y_train, y_pred_train_rf)\n",
    "test_r2_rf = r2_score(y_test, y_pred_test_rf)\n",
    "\n",
    "print('Random Forest:')\n",
    "print(f'Train RMSE: {train_rmse_rf}, Test RMSE: {test_rmse_rf}')\n",
    "print(f'Train R²: {train_r2_rf}, Test R²: {test_r2_rf}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization for Linear Regression\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(y_test, y_pred_test_lr, alpha=0.7, label='Predicted vs Actual (LR)')\n",
    "plt.xlabel('Actual Yield')\n",
    "plt.ylabel('Predicted Yield')\n",
    "plt.title('Actual vs Predicted Yield - Linear Regression')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization for Random Forest\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(y_test, y_pred_test_rf, alpha=0.7, label='Predicted vs Actual (RF)')\n",
    "plt.xlabel('Actual Yield')\n",
    "plt.ylabel('Predicted Yield')\n",
    "plt.title('Actual vs Predicted Yield - Random Forest')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
